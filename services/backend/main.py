"""
CivicSense FastAPI Backend - Real-Time Public Safety & Services Intelligence Copilot
Main application entry point with WebSocket support for chatbot.
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import asyncio
import json
from typing import Dict, Set
from datetime import datetime, timezone
import uvicorn

from config import settings
from logger import logger
from exceptions import CivicSenseException
from kafka_consumer import KafkaConsumerManager
from query_handler import QueryHandler
from flink_consumer import FlinkAggregateConsumer
from news_client import news_client
from redis_client import redis_client
from models import (
    QueryRequest,
    QueryResponse,
    HealthResponse,
    RootResponse,
    ErrorResponse,
    WebSocketQueryMessage,
    WebSocketResponseMessage,
    WebSocketStatusMessage,
    WebSocketErrorMessage,
    WebSocketStatusMessage,
    WebSocketErrorMessage,
    WebSocketSystemMessage,
)
from pydantic import BaseModel, Field
from typing import List, Optional
from fastapi import Depends
from rate_limiter import RateLimiter


# --- Enterprise Mock Models ---
class AlertActionRequest(BaseModel):
    user_id: str = Field(..., description="ID of the user performing the action")
    note: Optional[str] = Field(None, description="Optional note for the audit log")


class UserProfile(BaseModel):
    user_id: str
    username: str
    role: str
    preferences: Dict[str, str]
    notification_settings: Dict[str, bool]


class FeedbackRequest(BaseModel):
    query_id: str
    rating: int = Field(..., ge=1, le=5)
    comment: Optional[str]


# WebSocket connection manager
class ConnectionManager:
    """Manages WebSocket connections for real-time chat."""

    def __init__(self):
        self.active_connections: Set[WebSocket] = set()

    async def connect(self, websocket: WebSocket):
        """Accept and register a new WebSocket connection."""
        await websocket.accept()
        self.active_connections.add(websocket)
        logger.info(f"New WebSocket connection. Total: {len(self.active_connections)}")

    def disconnect(self, websocket: WebSocket):
        """Remove a WebSocket connection."""
        self.active_connections.discard(websocket)
        logger.info(f"WebSocket disconnected. Total: {len(self.active_connections)}")

    async def send_personal_message(self, message: dict, websocket: WebSocket):
        """Send a message to a specific WebSocket connection."""
        try:
            await websocket.send_json(message)
        except Exception as e:
            logger.error(f"Error sending message: {e}")
            self.disconnect(websocket)

    async def broadcast(self, message: dict):
        """Broadcast a message to all connected clients."""
        disconnected = set()
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                logger.error(f"Error broadcasting to connection: {e}")
                disconnected.add(connection)

        # Clean up disconnected clients
        for conn in disconnected:
            self.disconnect(conn)


# Global instances
connection_manager = ConnectionManager()
kafka_consumer_manager: KafkaConsumerManager = None
query_handler: QueryHandler = None
flink_consumer: FlinkAggregateConsumer = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager for startup and shutdown."""
    global kafka_consumer_manager, query_handler, flink_consumer

    logger.info("Starting CivicSense backend...")

    # Initialize query handler
    query_handler = QueryHandler()
    logger.info("Query handler initialized")

    # Initialize Redis client
    await redis_client.connect()

    # Initialize and start Kafka consumer
    kafka_consumer_manager = KafkaConsumerManager(
        topics=[
            settings.KAFKA_TOPIC_IMPACT_SIGNALS, 
            settings.KAFKA_TOPIC_CHAT_OUTPUT,
            settings.KAFKA_TOPIC_EMERGENCY,
            settings.KAFKA_TOPIC_INFRASTRUCTURE,
            settings.KAFKA_TOPIC_TRANSIT,
            settings.KAFKA_TOPIC_EDUCATION
        ]
    )
    asyncio.create_task(consume_kafka_messages())
    logger.info("Kafka consumer started")

    # Initialize and start Flink aggregate consumer
    # flink_consumer = FlinkAggregateConsumer()
    # flink_consumer.start()
    # asyncio.create_task(update_flink_stats())
    logger.info("Flink aggregate consumer DISABLED (fallback mode)")

    yield

    # Cleanup on shutdown
    logger.info("Shutting down CivicSense backend...")
    if kafka_consumer_manager:
        kafka_consumer_manager.stop()
    if flink_consumer:
        flink_consumer.stop()
    await redis_client.close()
    logger.info("Shutdown complete")


# OpenAPI tags for endpoint organization
tags_metadata = [
    {"name": "Health", "description": "System health monitoring and liveness probes."},
    {
        "name": "Query",
        "description": "AI-powered civic intelligence engine (Gemini 2.0).",
    },
    {
        "name": "Real-Time Data",
        "description": "Streaming analytics from Apache Flink SQL and Kafka.",
    },
    {
        "name": "Context",
        "description": "Environmental context data (Weather, Location) for adaptive personalization.",
    },
    {
        "name": "Alerts",
        "description": "Enterprise alert lifecycle management (Acknowledge, Dismiss, Audit).",
    },
    {"name": "User Management", "description": "User profile and preference settings."},
]

# Create FastAPI app
app = FastAPI(
    title="CivicSense API 2025 (Enterprise Edition)",
    description="""
# Real-Time Public Safety & Services Intelligence Copilot

**CivicSense 2025** is an enterprise-grade, event-driven platform that transforms live city data streams into actionable public safety guidance.

## ðŸš€ Key Capabilities

- **ðŸ§  Gemini 2.0 Powered**: Next-generation multi-agent AI for faster, more accurate reasoning.
- **âš¡ Flink SQL Analytics**: Sub-second event processing and aggregation.
- **ðŸ“¡ Data in Motion**: Direct integration with Confluent Cloud Kafka.
- **ðŸŽ¯ Context-Aware**: Adapts responses to user persona (Parent, Senior, Responder).
- **ðŸš€ High-Speed Caching**: Redis-integrated caching for weather/news and intelligent rate limiting.

## ðŸ›  Technology Stack

- **Streaming**: Confluent Cloud (Kafka) + Apache Flink SQL
- **AI/ML**: Google Vertex AI (Gemini 2.0 Flash) + Multi-Agent Orchestration
- **Data Store**: MongoDB Atlas (Vector Search) + Redis (Cache & Rate Limit)
- **API**: FastAPI (Async Python)

## ðŸ“Š Performance Metrics

- **Event-to-Insight Latency**: < 500ms
- **Query Processing**: ~1.2s avg
- **System Uptime**: 99.99% targeted
    """,
    version="2.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_tags=tags_metadata,
    contact={
        "name": "CivicSense GitHub",
        "url": "https://github.com/samalpartha/CivicSense",
    },
    license_info={
        "name": "Apache 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.html",
    },
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS.split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)



import json

import httpx
import time


@app.get(
    "/api/weather",
    tags=["Context"],
    summary="Get Local Weather Context",
    description="""
    Retrieves real-time weather data to provide environmental ground truth for AI agents.
    
    Features:
    - **Open-Meteo Integration**: Live temperature, wind, and conditions.
    - **Smart Caching**: 5-minute TTL to respect API limits.
    - **Fallback Mode**: Returns simulated data if external API fails.
    """,
)
async def get_weather(
    lat: float = 40.7128, lon: float = -74.0060, city: str = "New York"
):
    redis_key = f"weather:{city.lower().replace(' ', '_')}"

    # Check Redis cache
    try:
        cached_data = await redis_client.get(redis_key)
        if cached_data:
            logger.info(f"Returning cached weather for {city}")
            response = json.loads(cached_data)
            response["cached"] = True
            return response
    except Exception as e:
        logger.warning(f"Redis get failed: {e}")

    try:
        async with httpx.AsyncClient() as client:
            # Open-Meteo Free API
            url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current=temperature_2m,relative_humidity_2m,weather_code,wind_speed_10m&temperature_unit=fahrenheit&wind_speed_unit=mph"
            resp = await client.get(url, timeout=5.0)
            resp.raise_for_status()
            data = resp.json()

            # Map WMO codes to text (simplified)
            wmo_code = data["current"]["weather_code"]
            condition = "Clear"
            if wmo_code in [1, 2, 3]:
                condition = "Partly Cloudy"
            elif wmo_code in [45, 48]:
                condition = "Foggy"
            elif wmo_code in [51, 53, 55, 56, 57, 61, 63, 65]:
                condition = "Rainy"
            elif wmo_code in [71, 73, 75, 77]:
                condition = "Snowy"
            elif wmo_code >= 95:
                condition = "Thunderstorm"

            weather_data = {
                "location": city,
                "observed_at": data["current"]["time"],
                "temp_f": round(data["current"]["temperature_2m"]),
                "condition": condition,
                "wind_mph": round(data["current"]["wind_speed_10m"]),
                "humidity": data["current"]["relative_humidity_2m"],
                "source": "Open-Meteo",
                "cached": False,
            }

            # Cache in Redis for 5 minutes
            try:
                await redis_client.set(redis_key, json.dumps(weather_data), expire=300)
            except Exception as e:
                logger.warning(f"Redis set failed: {e}")

            return weather_data

    except Exception as e:
        logger.error(f"Weather API error: {e}")
        # Fallback to demo snapshot if API fails
        return {
            "location": city,
            "observed_at": "Demo Snapshot",
            "temp_f": 72,
            "condition": "Partly Cloudy (Simulated)",
            "wind_mph": 10,
            "humidity": 45,
            "source": "DemoSnapshot",
            "cached": False,
        }


async def update_flink_stats():
    """Background task to consume Flink-aggregated statistics."""
    logger.info("Starting Flink statistics update loop...")
    try:
        async for stats in flink_consumer.consume_aggregates():
            # Stats are updated in-memory and available via get_current_stats()
            logger.debug(
                f"Flink stats updated: {stats['events_today']} events, {stats['active_alerts']} alerts"
            )
    except Exception as e:
        logger.error(f"Error in Flink stats update loop: {e}")


@app.get(
    "/api/stats/realtime",
    tags=["Real-Time Data"],
    summary="Streaming Civic Analytics",
    description="""
    Delivers sub-second aggregated insights from Apache Flink SQL.
    
    Data Pipeline:
    1. **Ingest**: Raw events from Kafka topic `civic-events`
    2. **Process**: Flink SQL windowing (5-min tumbling)
    3. **Serve**: Immediate availability for dashboard
    
    Metrics:
    - Active global alerts
    - Event clustering by risk area
    - Severity distribution
    
    Returns:
        dict: Real-time statistics including:
            - active_alerts: Count of high-severity events
            - events_today: Total events processed in current window
            - high_risk_areas: List of areas with critical event clustering
            - event_types_breakdown: Distribution by event category
            - last_update: Timestamp of last Flink aggregation
    """,
)
async def get_realtime_stats():
    if not flink_consumer or not flink_consumer.is_running():
        return {
            "status": "fallback_mode_active",
            "message": "Flink consumer not initialized (waiting for infrastructure)",
            "fallback_mode": True,
            "active_alerts": 3,
            "events_today": 14,
            "high_risk_areas": [],
            "source": "Fallback (Demo Mode)",
        }

    stats = flink_consumer.get_current_stats()

    return {
        **stats,
        "status": "live",
        "window_type": "5-minute tumbling window",
        "processing_engine": "Apache Flink SQL",
    }


@app.get(
    "/api/news",
    tags=["Real-Time Data"],
    summary="Get Local Safety News",
    description="""
    Fetches real-time news articles related to public safety, emergencies, and traffic from NewsData.io.
    Results are cached for 15 minutes to respect API rate limits.
    """,
)
async def get_news(query: str = "safety OR emergency OR traffic", country: str = "us"):
    """
    Get latest safety-related news.
    """
    try:
        articles = await news_client.get_latest_news(query=query, country=country)
        return {"status": "success", "articles": articles}
    except Exception as e:
        logger.error(f"Error serving news: {e}")
        return {"status": "error", "message": str(e), "articles": []}


async def consume_kafka_messages():
    """Background task to consume Kafka messages and broadcast to WebSocket clients."""
    logger.info("Starting Kafka message consumption...")

    try:
        async for message in kafka_consumer_manager.consume():
            if message:
                # Broadcast impact signals and chat outputs to all connected clients
                await connection_manager.broadcast(
                    {
                        "type": "kafka_update",
                        "topic": message.get("topic"),
                        "data": message.get("value"),
                    }
                )
    except Exception as e:
        logger.error(f"Error in Kafka consumption: {e}")


@app.get(
    "/",
    response_model=RootResponse,
    tags=["Health"],
    summary="Root endpoint",
    description="Basic service information and health status. Use this endpoint to verify the API is accessible.",
    responses={
        200: {
            "description": "Service is running and accessible",
            "content": {
                "application/json": {
                    "example": {
                        "service": "CivicSense Backend",
                        "status": "healthy",
                        "version": "1.0.0",
                    }
                }
            },
        }
    },
)
async def root() -> RootResponse:
    """
    Root endpoint providing basic service information.

    Returns basic metadata about the CivicSense API including service name,
    current status, and version number.
    """
    return RootResponse(service="CivicSense Backend", status="healthy", version="1.0.0")


@app.get(
    "/health",
    response_model=HealthResponse,
    tags=["Health"],
    summary="Detailed health check",
    description="""
    Comprehensive health status of the CivicSense backend service.
    
    This endpoint reports the status of all critical components:
    - Kafka consumer connection status
    - Number of active WebSocket connections
    - AI query handler initialization status
    
    Use this endpoint for monitoring, load balancing decisions, and troubleshooting.
    """,
    responses={
        200: {
            "description": "Health status retrieved successfully",
            "content": {
                "application/json": {
                    "example": {
                        "status": "healthy",
                        "kafka_connected": True,
                        "active_connections": 5,
                        "query_handler_ready": True,
                    }
                }
            },
        }
    },
)
async def health() -> HealthResponse:
    """
    Detailed health check endpoint.

    Returns comprehensive status information about all backend components
    including Kafka connectivity, active WebSocket connections, and AI
    query handler readiness.
    """
    return HealthResponse(
        status="healthy",
        kafka_connected=(
            kafka_consumer_manager.is_running() if kafka_consumer_manager else False
        ),
        active_connections=len(connection_manager.active_connections),
        query_handler_ready=query_handler is not None,
    )


@app.websocket("/ws/chat")
async def websocket_chat(websocket: WebSocket):
    """
    **Real-Time Contextual AI Copilot Interface**

    Establishes a bidirectional WebSocket connection for the CivicSense AI Copilot.

    ### Capabilities
    - **Live Q&A**: Submit queries about safety, transit, and services.
    - **Proactive Alerts**: Receive push notifications for critical events.
    - **Session Context**: maintains conversation history.

    ### Protocol
    Messages must be JSON. See full documentation for schema.


    ## Connection Flow

    1. Client connects to `ws://localhost:8000/ws/chat`
    2. Server accepts and sends welcome message (type: `system`)
    3. Client can send queries (type: `query`)
    4. Server processes and responds (type: `response`, `status`, or `error`)
    5. Server broadcasts live Kafka updates (type: `kafka_update`)

    ## Message Types

    ### Client â†’ Server

    **Query Message**:
    ```json
    {
        "type": "query",
        "message": "Is it safe to go outside?",
        "context": {
            "user_type": "parent",
            "location": "Downtown",
            "language": "en"
        }
    }
    ```

    **Ping Message** (keep-alive):
    ```json
    {
        "type": "ping"
    }
    ```

    ### Server â†’ Client

    **System Message** (on connect):
    ```json
    {
        "type": "system",
        "message": "Connected to CivicSense. Ask me about safety, transit, emergencies, or services."
    }
    ```

    **Status Message** (processing):
    ```json
    {
        "type": "status",
        "message": "Processing your question..."
    }
    ```

    **Response Message** (AI answer):
    ```json
    {
        "type": "response",
        "message": "Based on current conditions...",
        "sources": ["Emergency Management Guide"],
        "severity": "low",
        "affected_areas": ["Downtown"],
        "timestamp": "2025-12-25T10:30:00"
    }
    ```

    **Error Message**:
    ```json
    {
        "type": "error",
        "message": "I'm having trouble processing your question."
    }
    ```

    **Kafka Update** (live events):
    ```json
    {
        "type": "kafka_update",
        "topic": "impact_signals",
        "data": { ... }
    }
    ```

    **Pong Message** (keep-alive response):
    ```json
    {
        "type": "pong"
    }
    ```

    ## Features

    - **Real-time**: Instant query processing and response delivery
    - **Bidirectional**: Server can push updates without client request
    - **Live Events**: Automatic broadcast of streaming Kafka events
    - **Keep-alive**: Ping/pong for connection health monitoring
    - **Error Handling**: Graceful error messages for invalid inputs

    ## Connection Management

    - Automatic reconnection recommended (client-side)
    - Max connection time: Unlimited
    - Idle timeout: None (use ping/pong)
    - Max message size: 1MB
    """
    await connection_manager.connect(websocket)

    try:
        # Send welcome message
        await connection_manager.send_personal_message(
            {
                "type": "system",
                "message": "Connected to CivicSense. Ask me about safety, transit, emergencies, or services in your area.",
            },
            websocket,
        )

        while True:
            # Receive message from client
            data = await websocket.receive_text()

            try:
                message_data = json.loads(data)
                message_type = message_data.get("type")

                if message_type == "query":
                    # Send acknowledgment
                    await connection_manager.send_personal_message(
                        {"type": "status", "message": "Processing your question..."},
                        websocket,
                    )

                    # Process the query using AI agents
                    user_message = message_data.get("message", "")
                    context = message_data.get("context", {})

                    logger.info(f"Processing query: {user_message}")

                    try:
                        # Process query with streaming
                        async for update in query_handler.process_query_stream(user_message, context):
                            
                            if update["type"] == "metadata":
                                # Send initial metadata (sources, severity)
                                await connection_manager.send_personal_message(
                                    {
                                        "type": "response_start",
                                        "severity": update["severity"],
                                        "affected_areas": update["affected_areas"],
                                        "sources": update["sources"],
                                        "timestamp": datetime.now(timezone.utc).isoformat()
                                    },
                                    websocket
                                )
                                
                            elif update["type"] == "token":
                                # Send text chunk
                                await connection_manager.send_personal_message(
                                    {
                                        "type": "response_token",
                                        "token": update["token"]
                                    },
                                    websocket
                                )
                            
                            elif update["type"] == "error":
                                await connection_manager.send_personal_message(
                                    {
                                        "type": "error",
                                        "message": update["message"]
                                    },
                                    websocket
                                )

                        # Send completion signal
                        await connection_manager.send_personal_message(
                            {"type": "response_end"},
                            websocket
                        )

                    except Exception as e:
                        logger.error(f"Error processing query stream: {e}", exc_info=True)
                        await connection_manager.send_personal_message(
                            {
                                "type": "error",
                                "message": f"Error: {str(e)}",
                            },
                            websocket,
                        )

                elif message_type == "ping":
                    # Handle ping for connection keep-alive
                    await connection_manager.send_personal_message(
                        {"type": "pong"}, websocket
                    )

                else:
                    await connection_manager.send_personal_message(
                        {
                            "type": "error",
                            "message": f"Unknown message type: {message_type}",
                        },
                        websocket,
                    )

            except json.JSONDecodeError:
                await connection_manager.send_personal_message(
                    {
                        "type": "error",
                        "message": "Invalid message format. Please send valid JSON.",
                    },
                    websocket,
                )

    except WebSocketDisconnect:
        connection_manager.disconnect(websocket)
        logger.info("Client disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        connection_manager.disconnect(websocket)


@app.post(
    "/api/query",
    response_model=QueryResponse,
    tags=["Query"],
    summary="Submit a civic query",
    dependencies=[Depends(RateLimiter(times=5, seconds=60))],  # 5 requests per minute
    description="""
    Process a user query using CivicSense's multi-agent AI system.
    
    ## Processing Pipeline
    
    1. **Triage Agent**: Classifies the query by category and urgency
    2. **Vector Search**: Retrieves relevant civic guidelines from knowledge base
    3. **Impact Agent**: Assesses severity and identifies affected areas
    4. **Guidance Agent**: Generates clear, actionable response using RAG
    5. **Monitoring Agent**: Logs interaction for analytics
    
    ## Query Categories
    
    - `emergency`: Fire, weather alerts, public safety
    - `infrastructure`: Power, water, internet, roads
    - `education`: Schools, closures, safety
    - `transit`: Buses, trains, delays
    - `general`: Other civic inquiries
    
    ## User Types
    
    Responses are adapted based on user type:
    - `parent`: Safety-focused, decision-making guidance
    - `senior`: Simplified language, accessibility-aware
    - `worker`: Concise, commute-focused
    - `student`: Direct, peer-relevant
    - `general`: Balanced information
    
    ## Response Time
    
    Average: 2-3 seconds (includes AI reasoning + vector search)
    """,
    responses={
        200: {
            "description": "Query processed successfully",
            "content": {
                "application/json": {
                    "example": {
                        "answer": "Based on current conditions, schools are operating normally today. There are no weather alerts or safety concerns affecting the Downtown area. Your child can safely attend school.",
                        "category": "education",
                        "severity": "low",
                        "affected_areas": ["Downtown"],
                        "sources": ["School Closure Guidelines"],
                        "confidence": 0.92,
                        "timestamp": "2025-12-25T10:30:00.123456",
                        "processing_time_ms": 2543.21,
                    }
                }
            },
        },
        400: {
            "model": ErrorResponse,
            "description": "Invalid request (missing required fields)",
        },
        500: {
            "model": ErrorResponse,
            "description": "Internal server error during processing",
        },
    },
    status_code=status.HTTP_200_OK,
)
async def query_endpoint(query: QueryRequest) -> QueryResponse:
    """
    Process a civic query using multi-agent AI system.

    This endpoint provides an HTTP alternative to WebSocket for one-off queries.
    It processes the query through the complete AI pipeline and returns a
    comprehensive response with guidance, severity assessment, and source citations.

    Args:
        query: QueryRequest containing the user's message and optional context

    Returns:
        QueryResponse with AI-generated guidance and metadata

    Raises:
        HTTPException(400): If message is missing or invalid
        HTTPException(500): If processing fails
    """
    try:
        if not query.message or not query.message.strip():
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Message is required and cannot be empty",
            )

        # Extract context as dict
        context_dict = query.context.model_dump() if query.context else {}

        # Process query through AI pipeline
        response = await query_handler.process_query(query.message, context_dict)

        # Return structured response
        return QueryResponse(**response)

    except HTTPException:
        raise
    except CivicSenseException as e:
        logger.error(f"Error processing query: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to process query: {str(e)}",
        )
    except Exception as e:
        logger.error(f"Unexpected error processing query: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An unexpected error occurred while processing your query",
        )


# --- Enterprise Endpoints (Mock) ---


@app.post(
    "/api/alerts/{alert_id}/acknowledge",
    tags=["Alerts"],
    summary="Acknowledge Alert",
    description="Marks an alert as read/acknowledged for the current user session.",
)
async def acknowledge_alert(alert_id: str, action: AlertActionRequest):
    return {
        "status": "success",
        "alert_id": alert_id,
        "state": "acknowledged",
        "timestamp": "2025-12-26T20:00:00Z",
    }


@app.post(
    "/api/alerts/{alert_id}/dismiss",
    tags=["Alerts"],
    summary="Dismiss Alert",
    description="Dismisses an alert from the active dashboard view.",
)
async def dismiss_alert(alert_id: str, action: AlertActionRequest):
    return {
        "status": "success",
        "alert_id": alert_id,
        "state": "dismissed",
        "timestamp": "2025-12-26T20:00:00Z",
    }


@app.get(
    "/api/user/profile",
    response_model=UserProfile,
    tags=["User Management"],
    summary="Get User Profile",
    description="Retrieves the current authenticated user's profile and settings.",
)
async def get_user_profile():
    return UserProfile(
        user_id="u_12345",
        username="civil_servant_01",
        role="responder",
        preferences={"theme": "system", "language": "en"},
        notification_settings={"email": True, "sms": True, "push": False},
    )


@app.post(
    "/api/feedback",
    tags=["Query"],
    summary="Submit Response Feedback",
    description="Allows users to rate the quality of AI-generated guidance.",
)
async def submit_feedback(feedback: FeedbackRequest):
    logger.info(f"Received feedback for {feedback.query_id}: {feedback.rating}/5")
    return {"status": "recorded", "id": "fb_98765"}


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=False,
        log_level=settings.LOG_LEVEL.lower(),
    )
